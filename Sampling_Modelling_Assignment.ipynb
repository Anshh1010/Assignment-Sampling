{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8794f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "## Dataset splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "## Over-Sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "## Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "## KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "## SVM\n",
    "from sklearn.svm import SVC \n",
    "## Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "## Guassian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f68119",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc757d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "767    0\n",
       "768    0\n",
       "769    0\n",
       "770    0\n",
       "771    0\n",
       "Name: Class, Length: 772, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a779db90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 772 entries, 0 to 771\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    772 non-null    int64  \n",
      " 1   V1      772 non-null    float64\n",
      " 2   V2      772 non-null    float64\n",
      " 3   V3      772 non-null    float64\n",
      " 4   V4      772 non-null    float64\n",
      " 5   V5      772 non-null    float64\n",
      " 6   V6      772 non-null    float64\n",
      " 7   V7      772 non-null    float64\n",
      " 8   V8      772 non-null    float64\n",
      " 9   V9      772 non-null    float64\n",
      " 10  V10     772 non-null    float64\n",
      " 11  V11     772 non-null    float64\n",
      " 12  V12     772 non-null    float64\n",
      " 13  V13     772 non-null    float64\n",
      " 14  V14     772 non-null    float64\n",
      " 15  V15     772 non-null    float64\n",
      " 16  V16     772 non-null    float64\n",
      " 17  V17     772 non-null    float64\n",
      " 18  V18     772 non-null    float64\n",
      " 19  V19     772 non-null    float64\n",
      " 20  V20     772 non-null    float64\n",
      " 21  V21     772 non-null    float64\n",
      " 22  V22     772 non-null    float64\n",
      " 23  V23     772 non-null    float64\n",
      " 24  V24     772 non-null    float64\n",
      " 25  V25     772 non-null    float64\n",
      " 26  V26     772 non-null    float64\n",
      " 27  V27     772 non-null    float64\n",
      " 28  V28     772 non-null    float64\n",
      " 29  Amount  772 non-null    float64\n",
      " 30  Class   772 non-null    int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 187.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5090feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['Class'],axis=1)\n",
    "x=x.drop(['Time'],axis=1)\n",
    "y=df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad4ede8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>-0.572263</td>\n",
       "      <td>0.731748</td>\n",
       "      <td>1.541254</td>\n",
       "      <td>0.150506</td>\n",
       "      <td>1.108974</td>\n",
       "      <td>0.372152</td>\n",
       "      <td>1.084879</td>\n",
       "      <td>-0.146329</td>\n",
       "      <td>-0.274447</td>\n",
       "      <td>-0.663670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056544</td>\n",
       "      <td>-0.143508</td>\n",
       "      <td>-0.107582</td>\n",
       "      <td>-0.418263</td>\n",
       "      <td>-0.731029</td>\n",
       "      <td>0.877525</td>\n",
       "      <td>-0.364150</td>\n",
       "      <td>-0.177509</td>\n",
       "      <td>-0.256545</td>\n",
       "      <td>26.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>-1.296845</td>\n",
       "      <td>-0.511605</td>\n",
       "      <td>2.404726</td>\n",
       "      <td>-0.310762</td>\n",
       "      <td>-0.319551</td>\n",
       "      <td>-0.542842</td>\n",
       "      <td>-0.173310</td>\n",
       "      <td>0.260423</td>\n",
       "      <td>-1.202688</td>\n",
       "      <td>0.050584</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.349668</td>\n",
       "      <td>-0.071270</td>\n",
       "      <td>-0.161175</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.285390</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>-0.370130</td>\n",
       "      <td>0.043410</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>1.214170</td>\n",
       "      <td>0.210481</td>\n",
       "      <td>0.484651</td>\n",
       "      <td>0.479768</td>\n",
       "      <td>-0.261955</td>\n",
       "      <td>-0.527039</td>\n",
       "      <td>0.021782</td>\n",
       "      <td>-0.106888</td>\n",
       "      <td>-0.037631</td>\n",
       "      <td>-0.144073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071540</td>\n",
       "      <td>-0.224292</td>\n",
       "      <td>-0.594609</td>\n",
       "      <td>0.159877</td>\n",
       "      <td>0.091873</td>\n",
       "      <td>0.140964</td>\n",
       "      <td>0.227406</td>\n",
       "      <td>-0.017389</td>\n",
       "      <td>0.016030</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>1.267030</td>\n",
       "      <td>-0.071114</td>\n",
       "      <td>0.037680</td>\n",
       "      <td>0.512683</td>\n",
       "      <td>0.242392</td>\n",
       "      <td>0.705212</td>\n",
       "      <td>-0.226582</td>\n",
       "      <td>0.109483</td>\n",
       "      <td>0.657565</td>\n",
       "      <td>-0.276918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066990</td>\n",
       "      <td>-0.164468</td>\n",
       "      <td>-0.177225</td>\n",
       "      <td>-0.222918</td>\n",
       "      <td>-1.245505</td>\n",
       "      <td>0.678360</td>\n",
       "      <td>0.525059</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>12.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>1.153758</td>\n",
       "      <td>0.132273</td>\n",
       "      <td>0.382969</td>\n",
       "      <td>1.405063</td>\n",
       "      <td>-0.224287</td>\n",
       "      <td>-0.197295</td>\n",
       "      <td>0.020653</td>\n",
       "      <td>0.029260</td>\n",
       "      <td>0.412254</td>\n",
       "      <td>-0.103547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230877</td>\n",
       "      <td>-0.107809</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>-0.057041</td>\n",
       "      <td>0.073082</td>\n",
       "      <td>0.633977</td>\n",
       "      <td>-0.310685</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>13.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1    1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "767 -0.572263  0.731748  1.541254  0.150506  1.108974  0.372152  1.084879   \n",
       "768 -1.296845 -0.511605  2.404726 -0.310762 -0.319551 -0.542842 -0.173310   \n",
       "769  1.214170  0.210481  0.484651  0.479768 -0.261955 -0.527039  0.021782   \n",
       "770  1.267030 -0.071114  0.037680  0.512683  0.242392  0.705212 -0.226582   \n",
       "771  1.153758  0.132273  0.382969  1.405063 -0.224287 -0.197295  0.020653   \n",
       "\n",
       "           V8        V9       V10  ...       V20       V21       V22  \\\n",
       "0    0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838   \n",
       "1    0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672   \n",
       "2    0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679   \n",
       "3    0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274   \n",
       "4   -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "767 -0.146329 -0.274447 -0.663670  ...  0.056544 -0.143508 -0.107582   \n",
       "768  0.260423 -1.202688  0.050584  ... -0.349668 -0.071270 -0.161175   \n",
       "769 -0.106888 -0.037631 -0.144073  ... -0.071540 -0.224292 -0.594609   \n",
       "770  0.109483  0.657565 -0.276918  ... -0.066990 -0.164468 -0.177225   \n",
       "771  0.029260  0.412254 -0.103547  ... -0.230877 -0.107809 -0.125231   \n",
       "\n",
       "          V23       V24       V25       V26       V27       V28  Amount  \n",
       "0   -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1    0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2    0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3   -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4   -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "..        ...       ...       ...       ...       ...       ...     ...  \n",
       "767 -0.418263 -0.731029  0.877525 -0.364150 -0.177509 -0.256545   26.72  \n",
       "768  0.088496  0.285390  0.281069 -0.370130  0.043410  0.092318   80.00  \n",
       "769  0.159877  0.091873  0.140964  0.227406 -0.017389  0.016030    5.98  \n",
       "770 -0.222918 -1.245505  0.678360  0.525059  0.002920 -0.003333   12.36  \n",
       "771 -0.057041  0.073082  0.633977 -0.310685  0.033590  0.015250   13.79  \n",
       "\n",
       "[772 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fb79b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "767    0\n",
       "768    0\n",
       "769    0\n",
       "770    0\n",
       "771    0\n",
       "Name: Class, Length: 772, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ef6292e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,2):\n",
    "    print(y.value_counts()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74b602c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state = 2)\n",
    "X, y = sm.fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e4729a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['class']=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb966c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763\n",
      "763\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts()[0])\n",
    "print(y.value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dcad0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating sample size for Simple Random Sampling using formula \n",
    "## Sample size=(Z^2)*p*(1-p)/E^2\n",
    "Z=1.96\n",
    "p=0.5\n",
    "E=0.04\n",
    "SS=(Z**2)*p*(1-p)/(E**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1bde36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600.2499999999999"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd797e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    305\n",
      "0    296\n",
      "Name: class, dtype: int64\n",
      "78.00829875518673\n",
      "98.7551867219917\n",
      "93.7759336099585\n",
      "83.81742738589212\n",
      "90.04149377593362\n"
     ]
    }
   ],
   "source": [
    "## Simple Random Sampling\n",
    "srs=X.sample(n=601,random_state=42)\n",
    "x=srs.drop(['class'],axis=1)\n",
    "y=srs['class']\n",
    "print(y.value_counts())\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n",
    "## Making list for storing accuracies\n",
    "accuracies1=[]\n",
    "## Gaussian NB\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train, y_train)\n",
    "y_pred = GNB.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies1.append(accuracy_score(y_test, y_pred)*100)\n",
    "## Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 100)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies1.append(accuracy_score(y_test, y_pred)*100)\n",
    "## SVM\n",
    "svm = SVC(kernel='linear') \n",
    "svm.fit(x, y) \n",
    "y_pred = svm.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies1.append(accuracy_score(y_test, y_pred)*100)\n",
    "## KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies1.append(accuracy_score(y_test, y_pred)*100)\n",
    "## Logistic Regression\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies1.append(accuracy_score(y_test, y_pred)*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34950872",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating sample size for Stratified Sampling using formula \n",
    "## Sample size=(Z^2)*p*(1-p)/(E/S)^2\n",
    "Z=1.96\n",
    "p=0.5\n",
    "E=0.1\n",
    "S=2\n",
    "SS=(Z**2)*p*(1-p)/((E/S)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c07506a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384.1599999999999"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92d61812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    384\n",
      "1    384\n",
      "Name: class, dtype: int64\n",
      "74.02597402597402\n",
      "98.7012987012987\n",
      "95.77922077922078\n",
      "87.98701298701299\n",
      "92.53246753246754\n"
     ]
    }
   ],
   "source": [
    "## Stratified Sampling\n",
    "ss=X.groupby('class', group_keys=False).apply(lambda x: x.sample(384,replace=True,random_state=42))\n",
    "x=ss.drop(['class'],axis=1)\n",
    "y=ss['class']\n",
    "print(y.value_counts())\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n",
    "## Making list for storing accuracies\n",
    "accuracies2=[]\n",
    "## Gaussian NB\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train, y_train)\n",
    "y_pred = GNB.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies2.append(accuracy_score(y_test, y_pred)*100)\n",
    "## Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 100)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies2.append(accuracy_score(y_test, y_pred)*100)\n",
    "## SVM\n",
    "svm = SVC(kernel='linear') \n",
    "svm.fit(x, y) \n",
    "y_pred = svm.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies2.append(accuracy_score(y_test, y_pred)*100)\n",
    "## KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies2.append(accuracy_score(y_test, y_pred)*100)\n",
    "## Logistic Regression\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies2.append(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d9575b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    155\n",
      "1    151\n",
      "Name: class, dtype: int64\n",
      "77.23577235772358\n",
      "98.3739837398374\n",
      "93.4959349593496\n",
      "85.36585365853658\n",
      "92.6829268292683\n"
     ]
    }
   ],
   "source": [
    "## Systematic Sampling\n",
    "def systematic_sampling(df, step):\n",
    " \n",
    "    indexes = np.arange(0, len(df), step=step)\n",
    "    systematic_sample = df.iloc[indexes]\n",
    "    return systematic_sample\n",
    " \n",
    " \n",
    "# Obtain a systematic sample and save it in a new variable\n",
    "systematic_sample = systematic_sampling(X, 5)\n",
    "x=systematic_sample.drop(['class'],axis=1)\n",
    "y=systematic_sample['class']\n",
    "print(y.value_counts())\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n",
    "## Making list for storing accuracies\n",
    "accuracies3=[]\n",
    "## Gaussian NB\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train, y_train)\n",
    "y_pred = GNB.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies3.append(accuracy_score(y_test, y_pred)*100)\n",
    "## Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 100)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies3.append(accuracy_score(y_test, y_pred)*100)\n",
    "## SVM\n",
    "svm = SVC(kernel='linear') \n",
    "svm.fit(x, y) \n",
    "y_pred = svm.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies3.append(accuracy_score(y_test, y_pred)*100)\n",
    "## KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies3.append(accuracy_score(y_test, y_pred)*100)\n",
    "## Logistic Regression\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies3.append(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f741762e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    202\n",
      "1    198\n",
      "Name: class, dtype: int64\n",
      "85.625\n",
      "98.75\n",
      "95.625\n",
      "82.5\n",
      "93.125\n"
     ]
    }
   ],
   "source": [
    "## Cluster Sampling\n",
    "def Cluster_Sampling(df, cluster_size, n_clusters):\n",
    "    N = len(df)\n",
    "    K = int(N/cluster_size)\n",
    "    data = None\n",
    "    for k in range(K):\n",
    "        sample_k = df.sample(cluster_size)\n",
    "        sample_k[\"cluster\"] = np.repeat(k,len(sample_k))\n",
    "        df = df.drop(index = sample_k.index)\n",
    "        data = pd.concat([data,sample_k],axis = 0)\n",
    "    random_chosen_clusters = np.random.randint(0,K,size =n_clusters )\n",
    "    samples = data[data.cluster.isin(random_chosen_clusters)]\n",
    "    return(samples)\n",
    "cluster_sample = Cluster_Sampling(df = X, cluster_size = 20, n_clusters = 28)\n",
    "\n",
    "x=cluster_sample.drop(['class'],axis=1)\n",
    "y=cluster_sample['class']\n",
    "print(y.value_counts())\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n",
    "## Making list for storing accuracies\n",
    "accuracies4=[]\n",
    "## Gaussian NB\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train, y_train)\n",
    "y_pred = GNB.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies4.append(accuracy_score(y_test, y_pred)*100)\n",
    "## Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 100)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies4.append(accuracy_score(y_test, y_pred)*100)\n",
    "## SVM\n",
    "svm = SVC(kernel='linear') \n",
    "svm.fit(x, y) \n",
    "y_pred = svm.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies4.append(accuracy_score(y_test, y_pred)*100)\n",
    "## KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies4.append(accuracy_score(y_test, y_pred)*100)\n",
    "## Logistic Regression\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies4.append(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c779d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    130\n",
      "0    120\n",
      "Name: class, dtype: int64\n",
      "83.0\n",
      "98.0\n",
      "95.0\n",
      "80.0\n",
      "79.0\n"
     ]
    }
   ],
   "source": [
    "## Multi-Stage Sampling\n",
    "def Cluster_Sampling(df, cluster_size, n_clusters):\n",
    "    N = len(df)\n",
    "    K = int(N/cluster_size)\n",
    "    data = None\n",
    "    for k in range(K):\n",
    "        sample_k = df.sample(cluster_size)\n",
    "        sample_k[\"cluster\"] = np.repeat(k,len(sample_k))\n",
    "        df = df.drop(index = sample_k.index)\n",
    "        data = pd.concat([data,sample_k],axis = 0)\n",
    "    random_chosen_clusters = np.random.randint(0,K,size =n_clusters )\n",
    "    samples = data[data.cluster.isin(random_chosen_clusters)]\n",
    "    return(samples)\n",
    "cluster_sample = Cluster_Sampling(df = X, cluster_size = 20, n_clusters = 20)\n",
    "mix_sample = cluster_sample.sample(n = 250, random_state=42)\n",
    "x=mix_sample.drop(['class'],axis=1)\n",
    "y=mix_sample['class']\n",
    "print(y.value_counts())\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=1)\n",
    "## Making list for storing accuracies\n",
    "accuracies5=[]\n",
    "## Gaussian NB\n",
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train, y_train)\n",
    "y_pred = GNB.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies5.append(accuracy_score(y_test, y_pred)*100)\n",
    "## Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 100)  \n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies5.append(accuracy_score(y_test, y_pred)*100)\n",
    "## SVM\n",
    "svm = SVC(kernel='linear') \n",
    "svm.fit(x, y) \n",
    "y_pred = svm.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies5.append(accuracy_score(y_test, y_pred)*100)\n",
    "## KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies5.append(accuracy_score(y_test, y_pred)*100)\n",
    "## Logistic Regression\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)\n",
    "accuracies5.append(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ff26348",
   "metadata": {},
   "outputs": [],
   "source": [
    "Models=['Gaussian Naive Bayes','Random Forest Classifier','Support Vector Machines','K-Nearest-Neighbours','Logistic Regression Classifier']\n",
    "Accuracy_Scores=pd.DataFrame(Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b94330e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest-Neighbours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "0            Gaussian Naive Bayes\n",
       "1        Random Forest Classifier\n",
       "2         Support Vector Machines\n",
       "3            K-Nearest-Neighbours\n",
       "4  Logistic Regression Classifier"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eecc2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Scores['Simple Random Sampling']=accuracies1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb128f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Scores['Stratified Sampling']=accuracies2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fc46759",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Scores['Systematic Sampling']=accuracies3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ca0bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Scores['Cluster Sampling']=accuracies4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "133561bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Scores['Multi-Stage Sampling']=accuracies5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef7dd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_Scores.columns = ['Models', 'Simple Random Sampling', 'Stratified Sampling','Systematic Sampling','Cluster Sampling','Multi-Stage Sampling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb14e2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Simple Random Sampling</th>\n",
       "      <th>Stratified Sampling</th>\n",
       "      <th>Systematic Sampling</th>\n",
       "      <th>Cluster Sampling</th>\n",
       "      <th>Multi-Stage Sampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>78.008299</td>\n",
       "      <td>74.025974</td>\n",
       "      <td>77.235772</td>\n",
       "      <td>85.625</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>98.755187</td>\n",
       "      <td>98.701299</td>\n",
       "      <td>98.373984</td>\n",
       "      <td>98.750</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>93.775934</td>\n",
       "      <td>95.779221</td>\n",
       "      <td>93.495935</td>\n",
       "      <td>95.625</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest-Neighbours</td>\n",
       "      <td>83.817427</td>\n",
       "      <td>87.987013</td>\n",
       "      <td>85.365854</td>\n",
       "      <td>82.500</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>90.041494</td>\n",
       "      <td>92.532468</td>\n",
       "      <td>92.682927</td>\n",
       "      <td>93.125</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Models  Simple Random Sampling  \\\n",
       "0            Gaussian Naive Bayes               78.008299   \n",
       "1        Random Forest Classifier               98.755187   \n",
       "2         Support Vector Machines               93.775934   \n",
       "3            K-Nearest-Neighbours               83.817427   \n",
       "4  Logistic Regression Classifier               90.041494   \n",
       "\n",
       "   Stratified Sampling  Systematic Sampling  Cluster Sampling  \\\n",
       "0            74.025974            77.235772            85.625   \n",
       "1            98.701299            98.373984            98.750   \n",
       "2            95.779221            93.495935            95.625   \n",
       "3            87.987013            85.365854            82.500   \n",
       "4            92.532468            92.682927            93.125   \n",
       "\n",
       "   Multi-Stage Sampling  \n",
       "0                  83.0  \n",
       "1                  98.0  \n",
       "2                  95.0  \n",
       "3                  80.0  \n",
       "4                  79.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_Scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
